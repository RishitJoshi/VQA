{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcafbbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import itertools\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.parsing.preprocessing import STOPWORDS,remove_stopwords\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6797b923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1685f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7923d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.read_csv('merge.csv')\n",
    "img_train_dir = r\"E:\\VQA_Dataset\\train2014\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e45144",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d696bfa",
   "metadata": {},
   "source": [
    "# Genrating Answer Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0023ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = list(dict(sorted(merge_df['multiple_choice_answer'].value_counts().to_dict().items(),key=lambda x:x[1],reverse=True)).keys())[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50cae710",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df['multiple_choice_answer'] =  merge_df['multiple_choice_answer'].apply(lambda x: x if x in class_list else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddff22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = merge_df[merge_df['multiple_choice_answer'].apply(lambda x: len(x)>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd12f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3ef8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clasess:  1000\n",
      "Shape of Answer Vectors in Train Data:  (215375, 1000)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelBinarizer()\n",
    "answer_vector = label_encoder.fit_transform(merge_df['multiple_choice_answer'].apply(lambda x: x).values)\n",
    "\n",
    "ans_vocab = {l: i for i, l in enumerate(label_encoder.classes_)}\n",
    "print(\"Number of clasess: \", len(ans_vocab))\n",
    "print(\"Shape of Answer Vectors in Train Data: \", answer_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82a1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d57eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3cd798f",
   "metadata": {},
   "source": [
    "# Genrating Question Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ae3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_english(sentence):\n",
    "    periodStrip  = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
    "    commaStrip   = re.compile(\"(\\d)(\\,)(\\d)\")\n",
    "    punct        = [';', r\"/\", '[', ']', '\"', '{', '}',\n",
    "                    '(', ')', '=', '+', '\\\\', '_', '-',\n",
    "                    '>', '<', '@', '`', ',', '?', '!']\n",
    "    contractions = {\"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\": \"could've\", \"couldnt\": \"couldn't\", \\\n",
    "                    \"couldn'tve\": \"couldn't've\", \"couldnt've\": \"couldn't've\", \"didnt\": \"didn't\", \"doesnt\": \"doesn't\", \"dont\": \"don't\", \"hadnt\": \"hadn't\", \\\n",
    "                    \"hadnt've\": \"hadn't've\", \"hadn'tve\": \"hadn't've\", \"hasnt\": \"hasn't\", \"havent\": \"haven't\", \"hed\": \"he'd\", \"hed've\": \"he'd've\", \\\n",
    "                    \"he'dve\": \"he'd've\", \"hes\": \"he's\", \"howd\": \"how'd\", \"howll\": \"how'll\", \"hows\": \"how's\", \"Id've\": \"I'd've\", \"I'dve\": \"I'd've\", \\\n",
    "                    \"Im\": \"I'm\", \"Ive\": \"I've\", \"isnt\": \"isn't\", \"itd\": \"it'd\", \"itd've\": \"it'd've\", \"it'dve\": \"it'd've\", \"itll\": \"it'll\", \"let's\": \"let's\", \\\n",
    "                    \"maam\": \"ma'am\", \"mightnt\": \"mightn't\", \"mightnt've\": \"mightn't've\", \"mightn'tve\": \"mightn't've\", \"mightve\": \"might've\", \\\n",
    "                    \"mustnt\": \"mustn't\", \"mustve\": \"must've\", \"neednt\": \"needn't\", \"notve\": \"not've\", \"oclock\": \"o'clock\", \"oughtnt\": \"oughtn't\", \\\n",
    "                    \"ow's'at\": \"'ow's'at\", \"'ows'at\": \"'ow's'at\", \"'ow'sat\": \"'ow's'at\", \"shant\": \"shan't\", \"shed've\": \"she'd've\", \"she'dve\": \"she'd've\", \\\n",
    "                    \"she's\": \"she's\", \"shouldve\": \"should've\", \"shouldnt\": \"shouldn't\", \"shouldnt've\": \"shouldn't've\", \"shouldn'tve\": \"shouldn't've\", \\\n",
    "                    \"somebody'd\": \"somebodyd\", \"somebodyd've\": \"somebody'd've\", \"somebody'dve\": \"somebody'd've\", \"somebodyll\": \"somebody'll\", \\\n",
    "                    \"somebodys\": \"somebody's\", \"someoned\": \"someone'd\", \"someoned've\": \"someone'd've\", \"someone'dve\": \"someone'd've\", \\\n",
    "                    \"someonell\": \"someone'll\", \"someones\": \"someone's\", \"somethingd\": \"something'd\", \"somethingd've\": \"something'd've\", \\\n",
    "                    \"something'dve\": \"something'd've\", \"somethingll\": \"something'll\", \"thats\": \"that's\", \"thered\": \"there'd\", \"thered've\": \"there'd've\", \\\n",
    "                    \"there'dve\": \"there'd've\", \"therere\": \"there're\", \"theres\": \"there's\", \"theyd\": \"they'd\", \"theyd've\": \"they'd've\", \\\n",
    "                    \"they'dve\": \"they'd've\", \"theyll\": \"they'll\", \"theyre\": \"they're\", \"theyve\": \"they've\", \"twas\": \"'twas\", \"wasnt\": \"wasn't\", \\\n",
    "                    \"wed've\": \"we'd've\", \"we'dve\": \"we'd've\", \"weve\": \"we've\", \"werent\": \"weren't\", \"whatll\": \"what'll\", \"whatre\": \"what're\", \\\n",
    "                    \"whats\": \"what's\", \"whatve\": \"what've\", \"whens\": \"when's\", \"whered\": \"where'd\", \"wheres\": \"where's\", \"whereve\": \"where've\", \\\n",
    "                    \"whod\": \"who'd\", \"whod've\": \"who'd've\", \"who'dve\": \"who'd've\", \"wholl\": \"who'll\", \"whos\": \"who's\", \"whove\": \"who've\", \"whyll\": \"why'll\", \\\n",
    "                    \"whyre\": \"why're\", \"whys\": \"why's\", \"wont\": \"won't\", \"wouldve\": \"would've\", \"wouldnt\": \"wouldn't\", \"wouldnt've\": \"wouldn't've\", \\\n",
    "                    \"wouldn'tve\": \"wouldn't've\", \"yall\": \"y'all\", \"yall'll\": \"y'all'll\", \"y'allll\": \"y'all'll\", \"yall'd've\": \"y'all'd've\", \\\n",
    "                    \"y'alld've\": \"y'all'd've\", \"y'all'dve\": \"y'all'd've\", \"youd\": \"you'd\", \"youd've\": \"you'd've\", \"you'dve\": \"you'd've\", \\\n",
    "                    \"youll\": \"you'll\", \"youre\": \"you're\", \"youve\": \"you've\"}\n",
    "\n",
    "    inText = sentence.replace('\\n', ' ')\n",
    "    inText = inText.replace('\\t', ' ')\n",
    "    inText = inText.strip()\n",
    "    outText = inText\n",
    "    for p in punct:\n",
    "        if (p + ' ' in inText or ' ' + p in inText) or \\\n",
    "           (re.search(commaStrip, inText) != None):\n",
    "            outText = outText.replace(p, '')\n",
    "        else:\n",
    "            outText = outText.replace(p, ' ')\n",
    "    outText = periodStrip.sub(\"\", outText, re.UNICODE)\n",
    "    outText = outText.lower().split()\n",
    "    for wordId, word in enumerate(outText):\n",
    "        if word in contractions:\n",
    "            outText[wordId] = contractions[word]\n",
    "    outText = ' '.join(outText)\n",
    "    return outText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabc3e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df['question'] = merge_df['question'].apply(lambda x:preprocess_english(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af544a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac8fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in tokenizer: 12573\n",
      "Shape of Question Vectors in Train Data:  (215375, 22)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token = \"<unk>\", filters = '')\n",
    "tokenizer.fit_on_texts(merge_df['question'].values)\n",
    "question_seqs = tokenizer.texts_to_sequences(merge_df['question'].values)\n",
    "question_vector = tf.keras.preprocessing.sequence.pad_sequences(question_seqs, padding='post')\n",
    "print(\"Number of words in tokenizer:\", len(tokenizer.word_index))\n",
    "print(\"Shape of Question Vectors in Train Data: \", question_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dee425c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('question_vector.pickle','wb') as handle:\n",
    "    pickle.dump(question_vector,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddbc736b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vector.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdd917",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b87ffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 1,\n",
       " 'the': 2,\n",
       " 'is': 3,\n",
       " 'what': 4,\n",
       " 'are': 5,\n",
       " 'this': 6,\n",
       " 'in': 7,\n",
       " 'a': 8,\n",
       " 'on': 9,\n",
       " 'how': 10,\n",
       " 'many': 11,\n",
       " 'of': 12,\n",
       " 'color': 13,\n",
       " 'there': 14,\n",
       " 'man': 15,\n",
       " 'does': 16,\n",
       " 'people': 17,\n",
       " 'picture': 18,\n",
       " 'to': 19,\n",
       " 'wearing': 20,\n",
       " 'these': 21,\n",
       " 'it': 22,\n",
       " 'have': 23,\n",
       " 'person': 24,\n",
       " 'photo': 25,\n",
       " 'do': 26,\n",
       " 'where': 27,\n",
       " 'or': 28,\n",
       " 'kind': 29,\n",
       " 'you': 30,\n",
       " 'animal': 31,\n",
       " 'room': 32,\n",
       " 'woman': 33,\n",
       " 'doing': 34,\n",
       " 'they': 35,\n",
       " 'be': 36,\n",
       " 'animals': 37,\n",
       " 'holding': 38,\n",
       " 'type': 39,\n",
       " 'can': 40,\n",
       " 'dog': 41,\n",
       " 'cat': 42,\n",
       " 'any': 43,\n",
       " 'at': 44,\n",
       " 'for': 45,\n",
       " 'he': 46,\n",
       " 'water': 47,\n",
       " 'his': 48,\n",
       " 'train': 49,\n",
       " 'that': 50,\n",
       " 'see': 51,\n",
       " 'food': 52,\n",
       " 'an': 53,\n",
       " 'shirt': 54,\n",
       " 'which': 55,\n",
       " 'playing': 56,\n",
       " 'made': 57,\n",
       " 'sport': 58,\n",
       " 'bus': 59,\n",
       " 'sitting': 60,\n",
       " 'table': 61,\n",
       " 'plate': 62,\n",
       " \"man's\": 63,\n",
       " 'shown': 64,\n",
       " 'plane': 65,\n",
       " 'sign': 66,\n",
       " 'taken': 67,\n",
       " 'with': 68,\n",
       " 'look': 69,\n",
       " 'standing': 70,\n",
       " 'right': 71,\n",
       " 'pizza': 72,\n",
       " 'all': 73,\n",
       " 'left': 74,\n",
       " 'background': 75,\n",
       " 'boy': 76,\n",
       " 'being': 77,\n",
       " 'sky': 78,\n",
       " 'was': 79,\n",
       " 'white': 80,\n",
       " 'ground': 81,\n",
       " 'has': 82,\n",
       " 'day': 83,\n",
       " 'her': 84,\n",
       " 'she': 85,\n",
       " 'girl': 86,\n",
       " 'eating': 87,\n",
       " 'from': 88,\n",
       " 'and': 89,\n",
       " 'wall': 90,\n",
       " 'visible': 91,\n",
       " 'looking': 92,\n",
       " 'hand': 93,\n",
       " 'same': 94,\n",
       " 'like': 95,\n",
       " 'men': 96,\n",
       " 'bear': 97,\n",
       " 'image': 98,\n",
       " 'game': 99,\n",
       " 'here': 100,\n",
       " 'would': 101,\n",
       " 'red': 102,\n",
       " 'street': 103,\n",
       " 'toilet': 104,\n",
       " 'building': 105,\n",
       " 'out': 106,\n",
       " 'up': 107,\n",
       " 'riding': 108,\n",
       " 'top': 109,\n",
       " 'one': 110,\n",
       " 'bird': 111,\n",
       " 'going': 112,\n",
       " 'who': 113,\n",
       " 'time': 114,\n",
       " 'fruit': 115,\n",
       " 'number': 116,\n",
       " 'why': 117,\n",
       " 'trees': 118,\n",
       " 'child': 119,\n",
       " 'car': 120,\n",
       " 'light': 121,\n",
       " 'behind': 122,\n",
       " 'truck': 123,\n",
       " 'front': 124,\n",
       " 'horse': 125,\n",
       " 'scene': 126,\n",
       " 'green': 127,\n",
       " 'seen': 128,\n",
       " 'ball': 129,\n",
       " 'bed': 130,\n",
       " 'hair': 131,\n",
       " 'could': 132,\n",
       " 'black': 133,\n",
       " 'giraffe': 134,\n",
       " 'glasses': 135,\n",
       " 'elephant': 136,\n",
       " 'flowers': 137,\n",
       " 'hat': 138,\n",
       " 'cake': 139,\n",
       " 'their': 140,\n",
       " 'grass': 141,\n",
       " 'been': 142,\n",
       " 'vehicle': 143,\n",
       " 'floor': 144,\n",
       " 'open': 145,\n",
       " 'did': 146,\n",
       " 'bathroom': 147,\n",
       " 'pictured': 148,\n",
       " 'giraffes': 149,\n",
       " 'bike': 150,\n",
       " 'clock': 151,\n",
       " 'head': 152,\n",
       " 'lights': 153,\n",
       " 'object': 154,\n",
       " 'sunny': 155,\n",
       " 'horses': 156,\n",
       " 'two': 157,\n",
       " 'bench': 158,\n",
       " 'blue': 159,\n",
       " 'cars': 160,\n",
       " 'down': 161,\n",
       " 'outside': 162,\n",
       " 'shoes': 163,\n",
       " 'birds': 164,\n",
       " 'both': 165,\n",
       " 'elephants': 166,\n",
       " 'colors': 167,\n",
       " 'window': 168,\n",
       " 'umbrella': 169,\n",
       " 'old': 170,\n",
       " 'someone': 171,\n",
       " 'zebras': 172,\n",
       " 'computer': 173,\n",
       " 'flying': 174,\n",
       " 'baby': 175,\n",
       " 'boat': 176,\n",
       " 'side': 177,\n",
       " 'than': 178,\n",
       " 'happy': 179,\n",
       " 'meal': 180,\n",
       " 'snow': 181,\n",
       " 'anyone': 182,\n",
       " 'appear': 183,\n",
       " 'next': 184,\n",
       " 'used': 185,\n",
       " 'fence': 186,\n",
       " \"woman's\": 187,\n",
       " 'road': 188,\n",
       " 'eat': 189,\n",
       " 'kitchen': 190,\n",
       " 'clean': 191,\n",
       " 'real': 192,\n",
       " 'hydrant': 193,\n",
       " 'weather': 194,\n",
       " 'camera': 195,\n",
       " 'guy': 196,\n",
       " 'will': 197,\n",
       " 'tree': 198,\n",
       " 'zebra': 199,\n",
       " 'player': 200,\n",
       " 'air': 201,\n",
       " 'back': 202,\n",
       " 'tennis': 203,\n",
       " 'laptop': 204,\n",
       " 'windows': 205,\n",
       " 'shape': 206,\n",
       " 'phone': 207,\n",
       " 'by': 208,\n",
       " 'pants': 209,\n",
       " 'brand': 210,\n",
       " 'clouds': 211,\n",
       " 'direction': 212,\n",
       " 'vase': 213,\n",
       " 'yellow': 214,\n",
       " 'traffic': 215,\n",
       " 'moving': 216,\n",
       " 'cows': 217,\n",
       " 'fire': 218,\n",
       " 'more': 219,\n",
       " 'glass': 220,\n",
       " 'sheep': 221,\n",
       " 'under': 222,\n",
       " 'women': 223,\n",
       " 'beach': 224,\n",
       " 'cold': 225,\n",
       " 'motorcycle': 226,\n",
       " 'door': 227,\n",
       " 'bowl': 228,\n",
       " 'lady': 229,\n",
       " 'inside': 230,\n",
       " 'dogs': 231,\n",
       " 'place': 232,\n",
       " 'played': 233,\n",
       " 'tie': 234,\n",
       " 'other': 235,\n",
       " 'around': 236,\n",
       " 'house': 237,\n",
       " 'about': 238,\n",
       " 'area': 239,\n",
       " 'walking': 240,\n",
       " 'hot': 241,\n",
       " 'using': 242,\n",
       " 'facing': 243,\n",
       " 'chair': 244,\n",
       " 'laying': 245,\n",
       " 'raining': 246,\n",
       " 'bears': 247,\n",
       " 'different': 248,\n",
       " 'feet': 249,\n",
       " 'tv': 250,\n",
       " 'kite': 251,\n",
       " 'off': 252,\n",
       " 'season': 253,\n",
       " 'boats': 254,\n",
       " 'children': 255,\n",
       " 'eyes': 256,\n",
       " 'helmet': 257,\n",
       " 'bananas': 258,\n",
       " 'pattern': 259,\n",
       " 'hanging': 260,\n",
       " 'frisbee': 261,\n",
       " 'likely': 262,\n",
       " 'night': 263,\n",
       " 'mirror': 264,\n",
       " 'city': 265,\n",
       " 'sandwich': 266,\n",
       " 'hands': 267,\n",
       " 'chairs': 268,\n",
       " \"person's\": 269,\n",
       " 'face': 270,\n",
       " 'full': 271,\n",
       " 'over': 272,\n",
       " 'jacket': 273,\n",
       " 'sink': 274,\n",
       " 'daytime': 275,\n",
       " 'way': 276,\n",
       " 'umbrellas': 277,\n",
       " 'material': 278,\n",
       " 'signs': 279,\n",
       " 'healthy': 280,\n",
       " 'good': 281,\n",
       " 'wild': 282,\n",
       " 'new': 283,\n",
       " 'near': 284,\n",
       " 'skateboard': 285,\n",
       " 'country': 286,\n",
       " 'taking': 287,\n",
       " 'stop': 288,\n",
       " 'those': 289,\n",
       " 'cow': 290,\n",
       " 'sleeping': 291,\n",
       " 'planes': 292,\n",
       " 'cats': 293,\n",
       " 'little': 294,\n",
       " 'players': 295,\n",
       " 'orange': 296,\n",
       " 'items': 297,\n",
       " 'vegetable': 298,\n",
       " 'large': 299,\n",
       " 'parked': 300,\n",
       " 'drinking': 301,\n",
       " 'dish': 302,\n",
       " 'wheels': 303,\n",
       " 'shorts': 304,\n",
       " 'above': 305,\n",
       " 'item': 306,\n",
       " 'board': 307,\n",
       " 'clear': 308,\n",
       " 'girls': 309,\n",
       " 'vehicles': 310,\n",
       " 'running': 311,\n",
       " 'boys': 312,\n",
       " 'desk': 313,\n",
       " 'kids': 314,\n",
       " 'zoo': 315,\n",
       " 'meat': 316,\n",
       " 'most': 317,\n",
       " 'park': 318,\n",
       " 'home': 319,\n",
       " 'called': 320,\n",
       " 'skiing': 321,\n",
       " 'need': 322,\n",
       " 'sun': 323,\n",
       " 'each': 324,\n",
       " 'big': 325,\n",
       " 'kid': 326,\n",
       " 'walls': 327,\n",
       " 'cup': 328,\n",
       " 'long': 329,\n",
       " 'cloudy': 330,\n",
       " 'couch': 331,\n",
       " 'as': 332,\n",
       " 'think': 333,\n",
       " 'restaurant': 334,\n",
       " \"what's\": 335,\n",
       " 'closed': 336,\n",
       " 'team': 337,\n",
       " 'stove': 338,\n",
       " 'get': 339,\n",
       " 'field': 340,\n",
       " 'lot': 341,\n",
       " 'paper': 342,\n",
       " 'say': 343,\n",
       " 'name': 344,\n",
       " 'surfboard': 345,\n",
       " 'something': 346,\n",
       " 'make': 347,\n",
       " 'middle': 348,\n",
       " 'match': 349,\n",
       " 'use': 350,\n",
       " 'vegetables': 351,\n",
       " 'buses': 352,\n",
       " 'carrying': 353,\n",
       " 'plates': 354,\n",
       " 'bikes': 355,\n",
       " 'professional': 356,\n",
       " 'seat': 357,\n",
       " 'into': 358,\n",
       " 'batter': 359,\n",
       " 'hit': 360,\n",
       " 'having': 361,\n",
       " 'high': 362,\n",
       " 'bottle': 363,\n",
       " 'trying': 364,\n",
       " 'kites': 365,\n",
       " 'modern': 366,\n",
       " 'motion': 367,\n",
       " 'stripes': 368,\n",
       " 'smiling': 369,\n",
       " 'empty': 370,\n",
       " 'tracks': 371,\n",
       " 'baseball': 372,\n",
       " 'refrigerator': 373,\n",
       " 'fruits': 374,\n",
       " 'leaves': 375,\n",
       " 'shower': 376,\n",
       " 'wet': 377,\n",
       " 'present': 378,\n",
       " 'dressed': 379,\n",
       " 'small': 380,\n",
       " 'female': 381,\n",
       " 'its': 382,\n",
       " 'bottom': 383,\n",
       " 'ready': 384,\n",
       " 'flag': 385,\n",
       " 'young': 386,\n",
       " 'waiting': 387,\n",
       " 'teddy': 388,\n",
       " 'play': 389,\n",
       " 'bag': 390,\n",
       " 'airplane': 391,\n",
       " 'wine': 392,\n",
       " \"boy's\": 393,\n",
       " 'transportation': 394,\n",
       " 'counter': 395,\n",
       " 'surfer': 396,\n",
       " 'male': 397,\n",
       " 'fridge': 398,\n",
       " 'drink': 399,\n",
       " 'court': 400,\n",
       " 'donuts': 401,\n",
       " 'watching': 402,\n",
       " 'suitcase': 403,\n",
       " 'flower': 404,\n",
       " 'cut': 405,\n",
       " 'pillows': 406,\n",
       " 'just': 407,\n",
       " 'foreground': 408,\n",
       " 'if': 409,\n",
       " 'slices': 410,\n",
       " 'activity': 411,\n",
       " 'objects': 412,\n",
       " 'screen': 413,\n",
       " 'box': 414,\n",
       " 'tall': 415,\n",
       " 'tower': 416,\n",
       " 'not': 417,\n",
       " 'eaten': 418,\n",
       " 'parking': 419,\n",
       " \"girl's\": 420,\n",
       " 'main': 421,\n",
       " 'natural': 422,\n",
       " 'hats': 423,\n",
       " 'covering': 424,\n",
       " 'indoors': 425,\n",
       " 'oven': 426,\n",
       " 'ski': 427,\n",
       " 'bat': 428,\n",
       " 'go': 429,\n",
       " 'neck': 430,\n",
       " 'mouse': 431,\n",
       " 'types': 432,\n",
       " 'mouth': 433,\n",
       " 'pictures': 434,\n",
       " 'touching': 435,\n",
       " 'trains': 436,\n",
       " 'fall': 437,\n",
       " 'buildings': 438,\n",
       " 'dress': 439,\n",
       " 'shadow': 440,\n",
       " 'anything': 441,\n",
       " 'painted': 442,\n",
       " 'legs': 443,\n",
       " 'keyboard': 444,\n",
       " 'coffee': 445,\n",
       " 'turned': 446,\n",
       " 'thing': 447,\n",
       " \"cat's\": 448,\n",
       " 'toy': 449,\n",
       " 'getting': 450,\n",
       " 'should': 451,\n",
       " 'cutting': 452,\n",
       " 'motorcycles': 453,\n",
       " 'brown': 454,\n",
       " 'gender': 455,\n",
       " 'event': 456,\n",
       " 'safe': 457,\n",
       " 'through': 458,\n",
       " 'part': 459,\n",
       " 'surfing': 460,\n",
       " 'doors': 461,\n",
       " 'located': 462,\n",
       " 'stuffed': 463,\n",
       " 'plant': 464,\n",
       " 'television': 465,\n",
       " 'racket': 466,\n",
       " 'photograph': 467,\n",
       " 'coming': 468,\n",
       " 'recently': 469,\n",
       " 'closest': 470,\n",
       " 'things': 471,\n",
       " 'pieces': 472,\n",
       " 'waves': 473,\n",
       " 'design': 474,\n",
       " 'towels': 475,\n",
       " 'adult': 476,\n",
       " 'shirts': 477,\n",
       " 'wood': 478,\n",
       " 'candles': 479,\n",
       " 'reflection': 480,\n",
       " \"child's\": 481,\n",
       " 'size': 482,\n",
       " 'mountains': 483,\n",
       " 'sidewalk': 484,\n",
       " 'pink': 485,\n",
       " 'luggage': 486,\n",
       " 'scissors': 487,\n",
       " 'lit': 488,\n",
       " \"dog's\": 489,\n",
       " 'skier': 490,\n",
       " 'pointing': 491,\n",
       " 'surface': 492,\n",
       " 'overcast': 493,\n",
       " 'utensil': 494,\n",
       " 'banana': 495,\n",
       " 'outdoors': 496,\n",
       " 'take': 497,\n",
       " 'poles': 498,\n",
       " 'ocean': 499,\n",
       " 'enough': 500,\n",
       " 'everyone': 501,\n",
       " 'sunglasses': 502,\n",
       " 'winter': 503,\n",
       " 'lamp': 504,\n",
       " 'language': 505,\n",
       " 'written': 506,\n",
       " 'device': 507,\n",
       " 'socks': 508,\n",
       " 'microwave': 509,\n",
       " 'knife': 510,\n",
       " 'work': 511,\n",
       " 'dark': 512,\n",
       " 'cooked': 513,\n",
       " 'tail': 514,\n",
       " 'system': 515,\n",
       " 'wear': 516,\n",
       " 'cabinets': 517,\n",
       " 'station': 518,\n",
       " 'bottles': 519,\n",
       " 'body': 520,\n",
       " 'far': 521,\n",
       " 'dirty': 522,\n",
       " 'coat': 523,\n",
       " 'driving': 524,\n",
       " 'bridge': 525,\n",
       " 'well': 526,\n",
       " 'landing': 527,\n",
       " 'working': 528,\n",
       " 'computers': 529,\n",
       " 'uniform': 530,\n",
       " 'making': 531,\n",
       " 'fork': 532,\n",
       " 'ripe': 533,\n",
       " 'bread': 534,\n",
       " 'vegetarian': 535,\n",
       " 'plants': 536,\n",
       " 'ceiling': 537,\n",
       " 'passenger': 538,\n",
       " 'first': 539,\n",
       " 'letter': 540,\n",
       " 'cheese': 541,\n",
       " 'collar': 542,\n",
       " 'suit': 543,\n",
       " 'live': 544,\n",
       " 'hotel': 545,\n",
       " 'gear': 546,\n",
       " 'apples': 547,\n",
       " 'breed': 548,\n",
       " 'race': 549,\n",
       " 'warm': 550,\n",
       " 'them': 551,\n",
       " 'setting': 552,\n",
       " 'trash': 553,\n",
       " 'pole': 554,\n",
       " 'skateboarder': 555,\n",
       " 'store': 556,\n",
       " 'donut': 557,\n",
       " 'tiles': 558,\n",
       " 'shot': 559,\n",
       " 'calm': 560,\n",
       " 'corner': 561,\n",
       " 'depicted': 562,\n",
       " 'yet': 563,\n",
       " 'jumping': 564,\n",
       " 'curtains': 565,\n",
       " 'some': 566,\n",
       " 'summer': 567,\n",
       " 'lid': 568,\n",
       " 'fast': 569,\n",
       " 'lines': 570,\n",
       " 'lying': 571,\n",
       " 'alone': 572,\n",
       " 'clocks': 573,\n",
       " 'asleep': 574,\n",
       " 'still': 575,\n",
       " 'position': 576,\n",
       " 'snowing': 577,\n",
       " 'style': 578,\n",
       " 'normal': 579,\n",
       " 'center': 580,\n",
       " 'ride': 581,\n",
       " 'sand': 582,\n",
       " 'fun': 583,\n",
       " 'curtain': 584,\n",
       " 'between': 585,\n",
       " 'line': 586,\n",
       " 'cooking': 587,\n",
       " 'wave': 588,\n",
       " 'arm': 589,\n",
       " 'belong': 590,\n",
       " 'year': 591,\n",
       " 'trucks': 592,\n",
       " 'skiers': 593,\n",
       " 'books': 594,\n",
       " 'towel': 595,\n",
       " 'appliance': 596,\n",
       " 'covered': 597,\n",
       " 'land': 598,\n",
       " 'living': 599,\n",
       " 'busy': 600,\n",
       " 'away': 601,\n",
       " 'colored': 602,\n",
       " 'handed': 603,\n",
       " 'too': 604,\n",
       " 'catch': 605,\n",
       " 'breakfast': 606,\n",
       " 'attached': 607,\n",
       " 'cell': 608,\n",
       " 'benches': 609,\n",
       " 'mountain': 610,\n",
       " 'only': 611,\n",
       " 'skis': 612,\n",
       " 'beverage': 613,\n",
       " 'served': 614,\n",
       " 'rain': 615,\n",
       " \"it's\": 616,\n",
       " 'carrots': 617,\n",
       " 'pulling': 618,\n",
       " 'clothes': 619,\n",
       " 'short': 620,\n",
       " 'outfit': 621,\n",
       " 'throwing': 622,\n",
       " 'alive': 623,\n",
       " 'handle': 624,\n",
       " 'apple': 625,\n",
       " 'remote': 626,\n",
       " 'cast': 627,\n",
       " 'graffiti': 628,\n",
       " 'sit': 629,\n",
       " 'swimming': 630,\n",
       " 'vases': 631,\n",
       " 'tablecloth': 632,\n",
       " 'photographer': 633,\n",
       " 'stuff': 634,\n",
       " 'much': 635,\n",
       " 'close': 636,\n",
       " 'broccoli': 637,\n",
       " 'family': 638,\n",
       " 'public': 639,\n",
       " 'cups': 640,\n",
       " 'birthday': 641,\n",
       " 'writing': 642,\n",
       " 'flags': 643,\n",
       " 'taller': 644,\n",
       " 'arrow': 645,\n",
       " 'couple': 646,\n",
       " 'laptops': 647,\n",
       " 'basket': 648,\n",
       " 'fireplace': 649,\n",
       " 'gloves': 650,\n",
       " 'clothing': 651,\n",
       " 'deep': 652,\n",
       " 'showing': 653,\n",
       " 'might': 654,\n",
       " 'hill': 655,\n",
       " 'hungry': 656,\n",
       " 'dinner': 657,\n",
       " 'talking': 658,\n",
       " 'america': 659,\n",
       " 'roof': 660,\n",
       " 'airport': 661,\n",
       " 'when': 662,\n",
       " 'habitat': 663,\n",
       " 'party': 664,\n",
       " 'metal': 665,\n",
       " 'bicycle': 666,\n",
       " 'location': 667,\n",
       " 'lamps': 668,\n",
       " 'american': 669,\n",
       " 'jersey': 670,\n",
       " 'piece': 671,\n",
       " 'leaning': 672,\n",
       " 'seem': 673,\n",
       " 'during': 674,\n",
       " 'ears': 675,\n",
       " 'show': 676,\n",
       " 'plastic': 677,\n",
       " 'sad': 678,\n",
       " 'painting': 679,\n",
       " 'traveling': 680,\n",
       " 'resting': 681,\n",
       " 'very': 682,\n",
       " 'meter': 683,\n",
       " 'suitcases': 684,\n",
       " 'walk': 685,\n",
       " 'word': 686,\n",
       " 'blanket': 687,\n",
       " 'fly': 688,\n",
       " 'united': 689,\n",
       " 'pic': 690,\n",
       " 'colorful': 691,\n",
       " 'utensils': 692,\n",
       " 'adults': 693,\n",
       " 'liquid': 694,\n",
       " 'furniture': 695,\n",
       " 'office': 696,\n",
       " 'company': 697,\n",
       " 'flat': 698,\n",
       " 'human': 699,\n",
       " 'skateboarding': 700,\n",
       " 'wrist': 701,\n",
       " 'trick': 702,\n",
       " 'book': 703,\n",
       " 'skating': 704,\n",
       " 'dry': 705,\n",
       " 'probably': 706,\n",
       " 'carpet': 707,\n",
       " 'guys': 708,\n",
       " 'shelf': 709,\n",
       " 'shining': 710,\n",
       " 'english': 711,\n",
       " 'container': 712,\n",
       " 'dessert': 713,\n",
       " 'featured': 714,\n",
       " 'edible': 715,\n",
       " 'cabinet': 716,\n",
       " 'falling': 717,\n",
       " 'states': 718,\n",
       " 'display': 719,\n",
       " 'sort': 720,\n",
       " 'dishes': 721,\n",
       " 'cross': 722,\n",
       " 'distance': 723,\n",
       " 'cones': 724,\n",
       " 'oranges': 725,\n",
       " 'holiday': 726,\n",
       " 'salad': 727,\n",
       " 'tusks': 728,\n",
       " 'helmets': 729,\n",
       " 'grazing': 730,\n",
       " 'foot': 731,\n",
       " 'turn': 732,\n",
       " 'missing': 733,\n",
       " 'sinks': 734,\n",
       " 'safety': 735,\n",
       " 'were': 736,\n",
       " 'wetsuit': 737,\n",
       " 'rider': 738,\n",
       " 'throw': 739,\n",
       " 'pizzas': 740,\n",
       " 'considered': 741,\n",
       " 'pillow': 742,\n",
       " 'surfboards': 743,\n",
       " 'species': 744,\n",
       " 'purple': 745,\n",
       " 'tell': 746,\n",
       " 'seats': 747,\n",
       " 'watch': 748,\n",
       " 'shadows': 749,\n",
       " \"player's\": 750,\n",
       " 'round': 751,\n",
       " 'desert': 752,\n",
       " 'tile': 753,\n",
       " 'monitor': 754,\n",
       " 'straight': 755,\n",
       " 'police': 756,\n",
       " 'pot': 757,\n",
       " 'crowded': 758,\n",
       " 'three': 759,\n",
       " 'free': 760,\n",
       " 'now': 761,\n",
       " 'numbers': 762,\n",
       " 'gray': 763,\n",
       " 'spoon': 764,\n",
       " 'blurry': 765,\n",
       " 'video': 766,\n",
       " 'skater': 767,\n",
       " 'backpack': 768,\n",
       " 'nose': 769,\n",
       " 'cap': 770,\n",
       " 'heads': 771,\n",
       " 'rug': 772,\n",
       " 'passengers': 773,\n",
       " \"batter's\": 774,\n",
       " 'beds': 775,\n",
       " 'structure': 776,\n",
       " 'bowls': 777,\n",
       " 'fit': 778,\n",
       " 'jet': 779,\n",
       " 'mode': 780,\n",
       " 'engine': 781,\n",
       " 'contain': 782,\n",
       " 'pitcher': 783,\n",
       " \"someone's\": 784,\n",
       " 'half': 785,\n",
       " 'stand': 786,\n",
       " 'nighttime': 787,\n",
       " 'wooden': 788,\n",
       " 'monitors': 789,\n",
       " 'tires': 790,\n",
       " 'horns': 791,\n",
       " 'crossing': 792,\n",
       " 'school': 793,\n",
       " 'tray': 794,\n",
       " 'rural': 795,\n",
       " 'your': 796,\n",
       " 'driver': 797,\n",
       " 'focus': 798,\n",
       " 'know': 799,\n",
       " 'flooring': 800,\n",
       " 'river': 801,\n",
       " 'humans': 802,\n",
       " 'teeth': 803,\n",
       " 'phones': 804,\n",
       " 'environment': 805,\n",
       " 'view': 806,\n",
       " 'commercial': 807,\n",
       " 'snowboarding': 808,\n",
       " 'married': 809,\n",
       " 'screens': 810,\n",
       " 'bathtub': 811,\n",
       " 'business': 812,\n",
       " 'sofa': 813,\n",
       " 'displayed': 814,\n",
       " 'logo': 815,\n",
       " 'against': 816,\n",
       " 'double': 817,\n",
       " 'equipment': 818,\n",
       " 'currently': 819,\n",
       " 'boots': 820,\n",
       " 'statue': 821,\n",
       " 'forest': 822,\n",
       " 'rocks': 823,\n",
       " 'van': 824,\n",
       " 'sale': 825,\n",
       " 'toppings': 826,\n",
       " 'seated': 827,\n",
       " 'jeans': 828,\n",
       " 'jump': 829,\n",
       " 'bags': 830,\n",
       " 'lunch': 831,\n",
       " 'lake': 832,\n",
       " 'bright': 833,\n",
       " 'towards': 834,\n",
       " 'age': 835,\n",
       " 'foods': 836,\n",
       " 'dangerous': 837,\n",
       " 'dominant': 838,\n",
       " 'gas': 839,\n",
       " 'vest': 840,\n",
       " 'kinds': 841,\n",
       " 'us': 842,\n",
       " 'frame': 843,\n",
       " 'set': 844,\n",
       " 'comfortable': 845,\n",
       " 'nice': 846,\n",
       " 'grown': 847,\n",
       " 'stripe': 848,\n",
       " 'sauce': 849,\n",
       " 'urban': 850,\n",
       " 'soda': 851,\n",
       " 'celebrating': 852,\n",
       " 'appliances': 853,\n",
       " 'nearby': 854,\n",
       " 'another': 855,\n",
       " 'already': 856,\n",
       " 'want': 857,\n",
       " 'mirrors': 858,\n",
       " 'so': 859,\n",
       " 'track': 860,\n",
       " 'blinds': 861,\n",
       " 'church': 862,\n",
       " 'skirt': 863,\n",
       " 'catching': 864,\n",
       " 'post': 865,\n",
       " 'electric': 866,\n",
       " \"women's\": 867,\n",
       " 'mug': 868,\n",
       " 'participating': 869,\n",
       " 'faces': 870,\n",
       " 'mean': 871,\n",
       " 'shade': 872,\n",
       " 'beer': 873,\n",
       " 'doughnuts': 874,\n",
       " 'fur': 875,\n",
       " 'together': 876,\n",
       " 'tub': 877,\n",
       " 'dirt': 878,\n",
       " 'we': 879,\n",
       " 'military': 880,\n",
       " 'related': 881,\n",
       " 'ear': 882,\n",
       " 'messy': 883,\n",
       " 'spots': 884,\n",
       " 'beside': 885,\n",
       " 'farm': 886,\n",
       " 'ladies': 887,\n",
       " 'electronic': 888,\n",
       " 'bicycles': 889,\n",
       " 'airline': 890,\n",
       " 'across': 891,\n",
       " 'aircraft': 892,\n",
       " 'machine': 893,\n",
       " 'cover': 894,\n",
       " 'catcher': 895,\n",
       " 'striped': 896,\n",
       " 'fresh': 897,\n",
       " 'market': 898,\n",
       " 'reflected': 899,\n",
       " 'surfers': 900,\n",
       " 'shelves': 901,\n",
       " 'engines': 902,\n",
       " 'toys': 903,\n",
       " 'call': 904,\n",
       " 'below': 905,\n",
       " 'able': 906,\n",
       " 'skate': 907,\n",
       " 'older': 908,\n",
       " 't': 909,\n",
       " 'paint': 910,\n",
       " 'sliced': 911,\n",
       " 'whole': 912,\n",
       " 'group': 913,\n",
       " \"lady's\": 914,\n",
       " 'feeding': 915,\n",
       " 'cart': 916,\n",
       " 'stands': 917,\n",
       " 'snowboard': 918,\n",
       " 'spot': 919,\n",
       " 'flavor': 920,\n",
       " 'toothbrush': 921,\n",
       " 'steps': 922,\n",
       " 'fan': 923,\n",
       " 'broken': 924,\n",
       " 'art': 925,\n",
       " 'pan': 926,\n",
       " 'model': 927,\n",
       " \"animal's\": 928,\n",
       " 'reading': 929,\n",
       " 'pet': 930,\n",
       " \"bear's\": 931,\n",
       " 'wind': 932,\n",
       " \"giraffe's\": 933,\n",
       " 'owner': 934,\n",
       " 'represented': 935,\n",
       " 'besides': 936,\n",
       " 'letters': 937,\n",
       " 'space': 938,\n",
       " 'come': 939,\n",
       " 'toilets': 940,\n",
       " 'posing': 941,\n",
       " 'him': 942,\n",
       " 'ice': 943,\n",
       " 'restroom': 944,\n",
       " 'downhill': 945,\n",
       " 'signal': 946,\n",
       " 'arms': 947,\n",
       " 'trunk': 948,\n",
       " 'goggles': 949,\n",
       " 'put': 950,\n",
       " 'common': 951,\n",
       " 'sweater': 952,\n",
       " 'drive': 953,\n",
       " 'boards': 954,\n",
       " 'purse': 955,\n",
       " 'silver': 956,\n",
       " 'sticking': 957,\n",
       " 'rolls': 958,\n",
       " 'levels': 959,\n",
       " 'bedroom': 960,\n",
       " 'platform': 961,\n",
       " 'fighting': 962,\n",
       " 'christmas': 963,\n",
       " 'chocolate': 964,\n",
       " 'dining': 965,\n",
       " 'find': 966,\n",
       " 'stories': 967,\n",
       " 'crowd': 968,\n",
       " 'recent': 969,\n",
       " 'tomatoes': 970,\n",
       " 'typical': 971,\n",
       " 'hold': 972,\n",
       " 'purpose': 973,\n",
       " 'ties': 974,\n",
       " 'sheets': 975,\n",
       " 'power': 976,\n",
       " \"men's\": 977,\n",
       " 'wrapped': 978,\n",
       " '2': 979,\n",
       " 'leg': 980,\n",
       " 'balls': 981,\n",
       " 'tag': 982,\n",
       " 'represent': 983,\n",
       " 'shop': 984,\n",
       " 'ring': 985,\n",
       " 'second': 986,\n",
       " 'tied': 987,\n",
       " 'fingers': 988,\n",
       " 'riders': 989,\n",
       " 'before': 990,\n",
       " 'shoe': 991,\n",
       " 'filled': 992,\n",
       " \"horse's\": 993,\n",
       " 'bite': 994,\n",
       " 'fish': 995,\n",
       " 'beard': 996,\n",
       " 'last': 997,\n",
       " 'protective': 998,\n",
       " 'awake': 999,\n",
       " 'town': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd28ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e771d492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12573"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7cd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482868b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751fac11",
   "metadata": {},
   "source": [
    "# Extracting Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbd627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.io.decode_jpeg(img,channels=3)\n",
    "    img = tf.image.resize(img,(img_width,img_height))\n",
    "    img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "    img = img * (1./255)\n",
    "    return img,image_path\n",
    "\n",
    "def VGG19_Top():\n",
    "    model =tf.keras.applications.VGG19(include_top=False,weights='imagenet',input_shape=(img_width,img_height,3))\n",
    "    input_layer = model.input\n",
    "    hidden_layer = model.layers[-1].output\n",
    "    model = tf.keras.Model(input_layer, hidden_layer)\n",
    "    return model\n",
    "\n",
    "def generate_image_features(images):\n",
    "    model = VGG19_Top()\n",
    "    all_image_dict = {}\n",
    "    img_ds = tf.data.Dataset.from_tensor_slices(images)\n",
    "    img_ds = img_ds.map(load_img, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(16)\n",
    "\n",
    "    progress_bar = tqdm(total=len(images), desc=\"Processing images\")\n",
    "    \n",
    "    for batch_img, batch_path in img_ds:\n",
    "        batch_img_features = model(batch_img)\n",
    "\n",
    "        for img_features, path in zip(batch_img_features, batch_path):\n",
    "            image_path = path.numpy().decode(\"utf-8\")\n",
    "            all_image_dict[image_path] = img_features.numpy()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    with open(r\"E:\\VQA_Dataset\\all_image_dict.pickle\", 'wb') as handle:\n",
    "        pickle.dump(all_image_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return\n",
    "all_image_path = merge_df['image_id'].apply(lambda x:  img_train_dir +'\\\\' + 'COCO_train2014_' + '%012d.jpg' % (x)).unique()\n",
    "generate_image_features(all_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc603127",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_path = merge_df['image_id'].apply(lambda x:  img_train_dir +'\\\\' + 'COCO_train2014_' + '%012d.jpg' % (x)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88390ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"all_image_dict.pickle\", 'rb') as handle:\n",
    "    all_image_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc0979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imageTensor(img,ques):\n",
    "    img_tensor = all_image_dict[img.decode('utf-8')]\n",
    "    return img_tensor,ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ba2eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Dataset(all_image_path,question_vector,answer_vector):\n",
    "    # Combining image,questions and answers\n",
    "    combined_data = []\n",
    "    for i in range(len(all_image_path)):\n",
    "        combined_data.append((all_image_path[i], question_vector[i], answer_vector[i]))\n",
    "    \n",
    "    # Split image paths, question vector, and answer vector into training and validation sets\n",
    "    train_data, val_data = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #Unpacking training and validation data and converting tuples to numpy array\n",
    "    train_image_path, train_question_vector, train_answer_vector = zip(*train_data)\n",
    "    val_image_path, val_question_vector, val_answer_vector = zip(*val_data)\n",
    "    \n",
    "    train_image_path = np.array(train_image_path)\n",
    "    train_question_vector = np.array(train_question_vector)\n",
    "    train_answer_vector = np.array(train_answer_vector)\n",
    "    \n",
    "    val_image_path = np.array(val_image_path)\n",
    "    val_question_vector = np.array(val_answer_vector)\n",
    "    val_answer_vector = np.array(val_answer_vector)\n",
    "    \n",
    "    # Create training dataset\n",
    "    train_dataset_input = tf.data.Dataset.from_tensor_slices((train_image_path, train_question_vector.astype(np.float32)))\n",
    "    train_dataset_output = tf.data.Dataset.from_tensor_slices((train_answer_vector.astype(np.float32)))\n",
    "    train_dataset_input = train_dataset_input.map(lambda img, ques: tf.numpy_function(get_imageTensor, [img, ques], [tf.float32, tf.float32]),\n",
    "                                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    train_dataset_input = train_dataset_input.batch(BATCH_SIZE)\n",
    "    train_dataset_output = train_dataset_output.batch(BATCH_SIZE)\n",
    "    train_dataset = tf.data.Dataset.zip((train_dataset_input, train_dataset_output))\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    train_dataset.save('train_dataset.tfrecord')\n",
    "    \n",
    "    # Create validation dataset\n",
    "    val_dataset_input = tf.data.Dataset.from_tensor_slices((val_image_path, val_question_vector.astype(np.float32)))\n",
    "    val_dataset_output = tf.data.Dataset.from_tensor_slices((val_answer_vector.astype(np.float32)))\n",
    "    val_dataset_input = val_dataset_input.map(lambda img, ques: tf.numpy_function(get_imageTensor, [img, ques], [tf.float32, tf.float32]),\n",
    "                                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset_input = val_dataset_input.batch(BATCH_SIZE)\n",
    "    val_dataset_output = val_dataset_output.batch(BATCH_SIZE)\n",
    "    val_dataset = tf.data.Dataset.zip((val_dataset_input, val_dataset_output))\n",
    "    val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset.save('validation_dataset.tfrecord')\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed028f6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train,dataset_valid = Create_Dataset(all_image_path,question_vector,answer_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "cuda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
